# Document Similarity in Quora

### Project Background: 
Quora is a platform to ask questions and connect with people who contribute unique insights and quality answers. Sometimes people ask the same questions in different points in time. Quora supplied Kaggle with a labeled dataset where it gives two questions and provides a label whether these two questions are duplicates or not.

### Project Goal: 
Given two questions from Quora, predict if they are duplicates or not.

### Methods: 
Dataset was obtained from Kaggle. It has two files: train.csv and test.csv. The numbers of rows in the train and test data are  404289  and  2345795  respectively. I decided to work with the labeled data in train.csv as the main dataset, and then split it into a train and test set later. First, the questions data is filtered by converting to lowercase and special characters, removing spaces, HTML tags, and punctuations marks. Then, stop words were removed.  21  features were created from these questions such as number of words in question  1 , number of words in question  2 , etc; and four similarity features were calculated from unweighted/weighted TF-IDF Word2Vec and GloVe models. Then, exploratory data analysis (EDA) was performed on these generated features in order to check their distributions, correlations, and multicolinearity. Four machine learning algorithms were chosen: Logistic regression, Neural network, Random Forest, and XgBoost. These five machine learning algorithms were applied to two datasets. First and second datasets contain  21  features generated from before and a similarity score calculated from an unweighted/weighted TF-IDF Word2Vec model. Third and fourth datasets contain  21  features generated from before and a similarity score calculated from an unweighted/weighted TF-IDF GloVe model. Hence, we have a total of  16  models. Multiple metrics were chosen to judge the best model such as: accuracy, balanced accuracy, Matthew's Correlation Coefficients (MCC), log loss function, and training time. Confusion matrix, calibration curves, and AUC-ROC curves were plotted for the best model. Finally, feature importance is demonstrated for the best model.

### Results: 
The best performing model was Random Forest with unweighted Word2Vec embedding plus other generated features. An accuracy of 74.94% was obtained. The most important feature to the Random Forest model was the similarity calculated from an unweighted Word2Vec embedding. Other features that are generated by fuzzywuzzy were also important.

### How to Use:
Build a docker image from Dockerfile with the command: "docker build -t [image_name] .". Then create a container from the docker image created from the previous step by running the command: "docker run -it --name [container_name] [image_name]". Finally, open jupyter notebook in a browser and bypass token authentication by running the command: "jupyter notebook --NotebookApp.token='' --NotebookApp.password='' --no-browser --allow-root".

To get the data, https://www.kaggle.com/c/quora-question-pairs/data. To check eda, run eda.ipynb file. To train or load models, run models.ipynb file.


For bugs and questions, contact: saadi.cv4 at gmail.com